{
  
    
        "post0": {
            "title": "Predicting Heart Disease Using Maching Learning",
            "content": "The original source of the dataset is from Kaggle, which combines 5 heart datasets over 11 common features. However, this project uses a modified version of the dataset The original dataset can be found here . In this learning project, I followed along with notebooks created by Fares Sayah on Kaggle, and Karan Bhanot on Medium . Problem Definition . Given clinical parameters about a patient, can we predict whether or not they have heart disease? . Import Libraries . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns !pip install panel hvplot import hvplot.pandas from scipy import stats import sklearn %matplotlib inline sns.set_style(&quot;whitegrid&quot;) plt.style.use(&quot;fivethirtyeight&quot;) . Gather and Prepare the Data . heart_disease = pd.read_csv(&quot;heart-disease.csv&quot;) . heart_disease.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 303 entries, 0 to 302 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 age 303 non-null int64 1 sex 303 non-null int64 2 cp 303 non-null int64 3 trestbps 303 non-null int64 4 chol 303 non-null int64 5 fbs 303 non-null int64 6 restecg 303 non-null int64 7 thalach 303 non-null int64 8 exang 303 non-null int64 9 oldpeak 303 non-null float64 10 slope 303 non-null int64 11 ca 303 non-null int64 12 thal 303 non-null int64 13 target 303 non-null int64 dtypes: float64(1), int64(13) memory usage: 33.3 KB . Data Dictionary . age (age in years) | sex (1 = male; 0 = female) | cp (chest pain, based on scale of 0-3) 0: Typical angina | 1: Atypical angina (chest pain not related to heart) | 2: Non-anginal pain (usually esophageal spasms) | 3: Asymptomatic (chest pain with no signs of disease) | . | trestbps (resting systolic blood pressure, in mmHg) | chol (serum cholesterol in mg/dL) | fbs (fasting blood sugar; 0 = less than or equal to 126 mg/dL; 1 &gt; 126 mg/dL) | restecg (resting ECG) . 0: Nothing to note | 1: ST-T Wave abnormality | 2: Possible or definite left ventricular hypertrophy | . | thalach (maximum heart rate acheived on stress test, between 60-202) . | exang (exercise induced angina; 1 = yes; 0 = no) | oldpeak (amount of ST depression induced by exercise) | slope (slope of the peak exercise ST segment) 0: Upsloping | 1: Flatsloping | 2: Downsloping | . | ca (number of major vessels colored by flouroscopy, 0-3) | thal (thalium stress test) . 1-3: normal | 6: fixed defect | 7: reversible defect (no blood flow during exercise) | . | target (have heart disease = 1; no heart disease = 0) . | heart_disease.head() . age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal target . 0 63 | 1 | 3 | 145 | 233 | 1 | 0 | 150 | 0 | 2.3 | 0 | 0 | 1 | 1 | . 1 37 | 1 | 2 | 130 | 250 | 0 | 1 | 187 | 0 | 3.5 | 0 | 0 | 2 | 1 | . 2 41 | 0 | 1 | 130 | 204 | 0 | 0 | 172 | 0 | 1.4 | 2 | 0 | 2 | 1 | . 3 56 | 1 | 1 | 120 | 236 | 0 | 1 | 178 | 0 | 0.8 | 2 | 0 | 2 | 1 | . 4 57 | 0 | 0 | 120 | 354 | 0 | 1 | 163 | 1 | 0.6 | 2 | 0 | 2 | 1 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Exploratory Data Analysis (EDA) . What questions am I trying to solve? | What kind of data do I have, and how do I work with it? | What&#39;s missing from the data, and how to deal with it? | Where are the outliers and why are they important? | How can I add, change, or remove features to get more out of the data? | . heart_disease.shape . (303, 14) . pd.set_option(&quot;display.float&quot;, &quot;{:.2f}&quot;.format) heart_disease.describe() . age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal target . count 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | 303.00 | . mean 54.37 | 0.68 | 0.97 | 131.62 | 246.26 | 0.15 | 0.53 | 149.65 | 0.33 | 1.04 | 1.40 | 0.73 | 2.31 | 0.54 | . std 9.08 | 0.47 | 1.03 | 17.54 | 51.83 | 0.36 | 0.53 | 22.91 | 0.47 | 1.16 | 0.62 | 1.02 | 0.61 | 0.50 | . min 29.00 | 0.00 | 0.00 | 94.00 | 126.00 | 0.00 | 0.00 | 71.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25% 47.50 | 0.00 | 0.00 | 120.00 | 211.00 | 0.00 | 0.00 | 133.50 | 0.00 | 0.00 | 1.00 | 0.00 | 2.00 | 0.00 | . 50% 55.00 | 1.00 | 1.00 | 130.00 | 240.00 | 0.00 | 1.00 | 153.00 | 0.00 | 0.80 | 1.00 | 0.00 | 2.00 | 1.00 | . 75% 61.00 | 1.00 | 2.00 | 140.00 | 274.50 | 0.00 | 1.00 | 166.00 | 1.00 | 1.60 | 2.00 | 1.00 | 3.00 | 1.00 | . max 77.00 | 1.00 | 3.00 | 200.00 | 564.00 | 1.00 | 2.00 | 202.00 | 1.00 | 6.20 | 2.00 | 4.00 | 3.00 | 1.00 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; counts = heart_disease.target.value_counts() counts . 1 165 0 138 Name: target, dtype: int64 . p = sns.countplot(data=heart_disease, x=&quot;target&quot;) p.set_xlabel(&quot;Heart Disease&quot;) p.set_ylabel(&quot;Counts&quot;); . heart_disease.isna().sum() . age 0 sex 0 cp 0 trestbps 0 chol 0 fbs 0 restecg 0 thalach 0 exang 0 oldpeak 0 slope 0 ca 0 thal 0 target 0 dtype: int64 . Notes: . Looks like there are 165 people with heart disease, and 138 without, so the dataset is fairly balanced . | There are no null values . | . categorical_val = [] continuous_val = [] for column in heart_disease.columns: if len(heart_disease[column].unique()) &lt;= 10: categorical_val.append(column) else: continuous_val.append(column) categorical_val . [&#39;sex&#39;, &#39;cp&#39;, &#39;fbs&#39;, &#39;restecg&#39;, &#39;exang&#39;, &#39;slope&#39;, &#39;ca&#39;, &#39;thal&#39;, &#39;target&#39;] . continuous_val . [&#39;age&#39;, &#39;trestbps&#39;, &#39;chol&#39;, &#39;thalach&#39;, &#39;oldpeak&#39;] . p = sns.countplot(data=heart_disease, x=&quot;target&quot;, hue=&quot;sex&quot;) p.set_xlabel(&quot;Heart Disease&quot;) plt.legend(bbox_to_anchor=(1.05,1), labels=[&#39;Female&#39;, &#39;Male&#39;]); . p = sns.countplot(data=heart_disease, x=&quot;cp&quot;, hue=&quot;target&quot;) p.set_xlabel(&quot;Chest Pain&quot;) plt.legend(labels=[&quot;No heart disease&quot;, &quot;Heart Disease&quot;]); . Chest Pain (Based on scale of 0-3) . 0: Typical angina | 1: Atypical angina (chest pain not related to heart) | 2: Non-anginal pain (usually esophageal spasms) | 3: Asymptomatic (chest pain with no signs of disease) | . Histograms of Continuous Data . plt.figure(figsize=(15,15)) for i, column in enumerate(continuous_val, 1): plt.subplot(3,2,i) sns.histplot(data=heart_disease, x=column, hue=&quot;target&quot;, multiple=&quot;stack&quot;) #plt.legend(labels=[&quot;No Ht Disease&quot;, &quot;Heart Disease&quot;]); . trestbps : resting blood pressure | chol : serum cholesterol (mg/dL) | thalach : maximum heart rate acheived on stress test (60-202) | oldpeak : ST depression induced by exercise relative to rest | . Target: . 0 (blue) = no heart disease | 1 (orange) = heart disease | . Scatterplot of Heart Disease in Relation to Age and Cholesterol . plt.figure(figsize=(9,7)) plt.scatter(heart_disease.age[heart_disease.target == 1], heart_disease.chol[heart_disease.target == 1], c=&quot;salmon&quot;) plt.scatter(heart_disease.age[heart_disease.target == 0], heart_disease.chol[heart_disease.target == 0], c=&quot;lightblue&quot;) plt.title(&quot;Correlation of Heart Disease with Age and Cholesterol&quot;) plt.xlabel(&quot;Age&quot;) plt.ylabel(&quot;Cholesterol&quot;) plt.legend([&quot;Disease&quot;, &quot;No Disease&quot;]); . There is no obvious correlation between cholesterol levels and heart disease! . Correlation Matrix . corr_matrix = heart_disease.corr() fig, ax = plt.subplots(figsize=(15,15)) ax = sns.heatmap(corr_matrix, annot = True, linewidths = 0.5, fmt = &quot;.2f&quot;, cmap = &quot;YlGnBu&quot;); bottom, top = ax.get_ylim() ax.set_ylim(bottom + 0.5, top - 0.5) . (14.5, -0.5) . The presence of chest pain and thalach (highest pulse rate acheived on stress test) seem to have the highest correlations with the target value. . Fasting blood sugar and cholesterol have the lowest correlation with the target variable. . Data Processing . Create dummy values | Scale values | . categorical_val.remove(&#39;target&#39;) dataset = pd.get_dummies(heart_disease, columns = categorical_val) . dataset.head() . age trestbps chol thalach oldpeak target sex_0 sex_1 cp_0 cp_1 ... slope_2 ca_0 ca_1 ca_2 ca_3 ca_4 thal_0 thal_1 thal_2 thal_3 . 0 63 | 145 | 233 | 150 | 2.30 | 1 | 0 | 1 | 0 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | . 1 37 | 130 | 250 | 187 | 3.50 | 1 | 0 | 1 | 0 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 2 41 | 130 | 204 | 172 | 1.40 | 1 | 1 | 0 | 0 | 1 | ... | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 3 56 | 120 | 236 | 178 | 0.80 | 1 | 0 | 1 | 0 | 1 | ... | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 4 57 | 120 | 354 | 163 | 0.60 | 1 | 1 | 0 | 1 | 0 | ... | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 5 rows × 31 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; print(heart_disease.columns) print(dataset.columns) . Index([&#39;age&#39;, &#39;sex&#39;, &#39;cp&#39;, &#39;trestbps&#39;, &#39;chol&#39;, &#39;fbs&#39;, &#39;restecg&#39;, &#39;thalach&#39;, &#39;exang&#39;, &#39;oldpeak&#39;, &#39;slope&#39;, &#39;ca&#39;, &#39;thal&#39;, &#39;target&#39;], dtype=&#39;object&#39;) Index([&#39;age&#39;, &#39;trestbps&#39;, &#39;chol&#39;, &#39;thalach&#39;, &#39;oldpeak&#39;, &#39;target&#39;, &#39;sex_0&#39;, &#39;sex_1&#39;, &#39;cp_0&#39;, &#39;cp_1&#39;, &#39;cp_2&#39;, &#39;cp_3&#39;, &#39;fbs_0&#39;, &#39;fbs_1&#39;, &#39;restecg_0&#39;, &#39;restecg_1&#39;, &#39;restecg_2&#39;, &#39;exang_0&#39;, &#39;exang_1&#39;, &#39;slope_0&#39;, &#39;slope_1&#39;, &#39;slope_2&#39;, &#39;ca_0&#39;, &#39;ca_1&#39;, &#39;ca_2&#39;, &#39;ca_3&#39;, &#39;ca_4&#39;, &#39;thal_0&#39;, &#39;thal_1&#39;, &#39;thal_2&#39;, &#39;thal_3&#39;], dtype=&#39;object&#39;) . from sklearn.preprocessing import StandardScaler s_sc = StandardScaler() col_to_scale = [&#39;age&#39;, &#39;trestbps&#39;, &#39;chol&#39;, &#39;thalach&#39;, &#39;oldpeak&#39;] dataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale]) . dataset.head() . age trestbps chol thalach oldpeak target sex_0 sex_1 cp_0 cp_1 ... slope_2 ca_0 ca_1 ca_2 ca_3 ca_4 thal_0 thal_1 thal_2 thal_3 . 0 0.95 | 0.76 | -0.26 | 0.02 | 1.09 | 1 | 0 | 1 | 0 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | . 1 -1.92 | -0.09 | 0.07 | 1.63 | 2.12 | 1 | 0 | 1 | 0 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 2 -1.47 | -0.09 | -0.82 | 0.98 | 0.31 | 1 | 1 | 0 | 0 | 1 | ... | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 3 0.18 | -0.66 | -0.20 | 1.24 | -0.21 | 1 | 0 | 1 | 0 | 1 | ... | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 4 0.29 | -0.66 | 2.08 | 0.58 | -0.38 | 1 | 1 | 0 | 1 | 0 | ... | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 5 rows × 31 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Build Models . Classification Report Template . from sklearn.metrics import accuracy_score, confusion_matrix, classification_report def print_score(clf, X_train, y_train, X_test, y_test, train=True): if train: pred = clf.predict(X_train) clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True)) print(&quot;Train Result: n================================================&quot;) print(f&quot;Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%&quot;) print(&quot;_______________________________________________&quot;) print(f&quot;CLASSIFICATION REPORT: n{clf_report}&quot;) print(&quot;_______________________________________________&quot;) print(f&quot;Confusion Matrix: n {confusion_matrix(y_train, pred)} n&quot;) elif train==False: pred = clf.predict(X_test) clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True)) print(&quot;Test Result: n================================================&quot;) print(f&quot;Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%&quot;) print(&quot;_______________________________________________&quot;) print(f&quot;CLASSIFICATION REPORT: n{clf_report}&quot;) print(&quot;_______________________________________________&quot;) print(f&quot;Confusion Matrix: n {confusion_matrix(y_test, pred)} n&quot;) . Split Data into Train &amp; Test Data . from sklearn.model_selection import train_test_split X = dataset.drop(&#39;target&#39;, axis=1) y = dataset.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) . Now that the data is split into training and test sets, I can build machine learning models . Train the data on the training set . Test on the test set . Here, I&#39;ll try 5 different machine learning models: . Logistic Regression | K-Nearest Neighbors Classifier | Support Vector machine | Decision Tree Classifier | Random Forest Classifier | . Model 1: Logistic Regression . from sklearn.linear_model import LogisticRegression lr_clf = LogisticRegression(solver=&#39;liblinear&#39;) lr_clf.fit(X_train, y_train) print_score(lr_clf, X_train, y_train, X_test, y_test, train=True) print_score(lr_clf, X_train, y_train, X_test, y_test, train=False) . Train Result: ================================================ Accuracy Score: 86.79% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.88 0.86 0.87 0.87 0.87 recall 0.82 0.90 0.87 0.86 0.87 f1-score 0.85 0.88 0.87 0.87 0.87 support 97.00 115.00 0.87 212.00 212.00 _______________________________________________ Confusion Matrix: [[ 80 17] [ 11 104]] Test Result: ================================================ Accuracy Score: 86.81% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.87 0.87 0.87 0.87 0.87 recall 0.83 0.90 0.87 0.86 0.87 f1-score 0.85 0.88 0.87 0.87 0.87 support 41.00 50.00 0.87 91.00 91.00 _______________________________________________ Confusion Matrix: [[34 7] [ 5 45]] . test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100 train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100 results_df = pd.DataFrame(data=[[&quot;Logistic Regression&quot;, train_score, test_score]], columns=[&#39;Model&#39;, &#39;Training Accuracy %&#39;, &#39;Testing Accuracy %&#39;]) results_df . Model Training Accuracy % Testing Accuracy % . 0 Logistic Regression | 86.79 | 86.81 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Model 2: K-Nearest Neighbors . from sklearn.neighbors import KNeighborsClassifier knn_clf = KNeighborsClassifier() knn_clf.fit(X_train, y_train) print_score(knn_clf, X_train, y_train, X_test, y_test, train=True) print_score(knn_clf, X_train, y_train, X_test, y_test, train=False) . Train Result: ================================================ Accuracy Score: 86.79% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.86 0.87 0.87 0.87 0.87 recall 0.85 0.89 0.87 0.87 0.87 f1-score 0.85 0.88 0.87 0.87 0.87 support 97.00 115.00 0.87 212.00 212.00 _______________________________________________ Confusion Matrix: [[ 82 15] [ 13 102]] Test Result: ================================================ Accuracy Score: 86.81% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.85 0.88 0.87 0.87 0.87 recall 0.85 0.88 0.87 0.87 0.87 f1-score 0.85 0.88 0.87 0.87 0.87 support 41.00 50.00 0.87 91.00 91.00 _______________________________________________ Confusion Matrix: [[35 6] [ 6 44]] . test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100 train_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100 results_df_2 = pd.DataFrame(data=[[&quot;K-nearest neighbors&quot;, train_score, test_score]], columns=[&#39;Model&#39;, &#39;Training Accuracy %&#39;, &#39;Testing Accuracy %&#39;]) results_df = results_df.append(results_df_2, ignore_index=True) results_df . Model Training Accuracy % Testing Accuracy % . 0 Logistic Regression | 86.79 | 86.81 | . 1 K-nearest neighbors | 86.79 | 86.81 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Model 3: Support Vector Machine . from sklearn.svm import SVC svm_clf = SVC(kernel=&#39;rbf&#39;, gamma=0.1, C=1.0) svm_clf.fit(X_train, y_train) print_score(svm_clf, X_train, y_train, X_test, y_test, train=True) print_score(svm_clf, X_train, y_train, X_test, y_test, train=False) . Train Result: ================================================ Accuracy Score: 93.40% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.94 0.93 0.93 0.93 0.93 recall 0.92 0.95 0.93 0.93 0.93 f1-score 0.93 0.94 0.93 0.93 0.93 support 97.00 115.00 0.93 212.00 212.00 _______________________________________________ Confusion Matrix: [[ 89 8] [ 6 109]] Test Result: ================================================ Accuracy Score: 87.91% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.86 0.90 0.88 0.88 0.88 recall 0.88 0.88 0.88 0.88 0.88 f1-score 0.87 0.89 0.88 0.88 0.88 support 41.00 50.00 0.88 91.00 91.00 _______________________________________________ Confusion Matrix: [[36 5] [ 6 44]] . test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100 train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100 results_df_2 = pd.DataFrame(data=[[&quot;Support Vector Machine&quot;, train_score, test_score]], columns=[&#39;Model&#39;, &#39;Training Accuracy %&#39;, &#39;Testing Accuracy %&#39;]) results_df = results_df.append(results_df_2, ignore_index=True) results_df . Model Training Accuracy % Testing Accuracy % . 0 Logistic Regression | 86.79 | 86.81 | . 1 K-nearest neighbors | 86.79 | 86.81 | . 2 Support Vector Machine | 93.40 | 87.91 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Model 4: Decision Tree Classifier . from sklearn.tree import DecisionTreeClassifier tree_clf = DecisionTreeClassifier(random_state=42) tree_clf.fit(X_train, y_train) print_score(tree_clf, X_train, y_train, X_test, y_test, train=True) print_score(tree_clf, X_train, y_train, X_test, y_test, train=False) . Train Result: ================================================ Accuracy Score: 100.00% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 1.00 1.00 1.00 1.00 1.00 recall 1.00 1.00 1.00 1.00 1.00 f1-score 1.00 1.00 1.00 1.00 1.00 support 97.00 115.00 1.00 212.00 212.00 _______________________________________________ Confusion Matrix: [[ 97 0] [ 0 115]] Test Result: ================================================ Accuracy Score: 78.02% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.72 0.84 0.78 0.78 0.79 recall 0.83 0.74 0.78 0.78 0.78 f1-score 0.77 0.79 0.78 0.78 0.78 support 41.00 50.00 0.78 91.00 91.00 _______________________________________________ Confusion Matrix: [[34 7] [13 37]] . test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100 train_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100 results_df_2 = pd.DataFrame(data=[[&quot;Decision Tree Classifier&quot;, train_score, test_score]], columns=[&#39;Model&#39;, &#39;Training Accuracy %&#39;, &#39;Testing Accuracy %&#39;]) results_df = results_df.append(results_df_2, ignore_index=True) results_df . Model Training Accuracy % Testing Accuracy % . 0 Logistic Regression | 86.79 | 86.81 | . 1 K-nearest neighbors | 86.79 | 86.81 | . 2 Support Vector Machine | 93.40 | 87.91 | . 3 Decision Tree Classifier | 100.00 | 78.02 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Model 5: Random Forest . from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import RandomizedSearchCV rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42) rf_clf.fit(X_train, y_train) print_score(rf_clf, X_train, y_train, X_test, y_test, train=True) print_score(rf_clf, X_train, y_train, X_test, y_test, train=False) . Train Result: ================================================ Accuracy Score: 100.00% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 1.00 1.00 1.00 1.00 1.00 recall 1.00 1.00 1.00 1.00 1.00 f1-score 1.00 1.00 1.00 1.00 1.00 support 97.00 115.00 1.00 212.00 212.00 _______________________________________________ Confusion Matrix: [[ 97 0] [ 0 115]] Test Result: ================================================ Accuracy Score: 82.42% _______________________________________________ CLASSIFICATION REPORT: 0 1 accuracy macro avg weighted avg precision 0.80 0.84 0.82 0.82 0.82 recall 0.80 0.84 0.82 0.82 0.82 f1-score 0.80 0.84 0.82 0.82 0.82 support 41.00 50.00 0.82 91.00 91.00 _______________________________________________ Confusion Matrix: [[33 8] [ 8 42]] . test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100 train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100 results_df_2 = pd.DataFrame(data=[[&quot;Random Forest Classifier&quot;, train_score, test_score]], columns=[&#39;Model&#39;, &#39;Training Accuracy %&#39;, &#39;Testing Accuracy %&#39;]) results_df = results_df.append(results_df_2, ignore_index=True) results_df . Model Training Accuracy % Testing Accuracy % . 0 Logistic Regression | 86.79 | 86.81 | . 1 K-nearest neighbors | 86.79 | 86.81 | . 2 Support Vector Machine | 93.40 | 87.91 | . 3 Decision Tree Classifier | 100.00 | 78.02 | . 4 Random Forest Classifier | 100.00 | 82.42 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Conclusions . The next step would be to explore hyperparameter tunings for the various ML models . From the preliminary data, though, it seems that Logistic Regression and Support Vector Machine models give the highest % testing accuracy, predicting heart disease from the features with a &gt; 86% accuracy. .",
            "url": "https://pkalnins.github.io/ws/data%20visualization/machine%20learning/2022/08/10/HeartDisease.html",
            "relUrl": "/data%20visualization/machine%20learning/2022/08/10/HeartDisease.html",
            "date": " • Aug 10, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Exploring Bias in Fandango Movie Ratings",
            "content": "Problem Statement: Is there a conflict of interest for a website that both sells movie tickets and displays review ratings? More specifically, does Fandango artifically display higher review ratings to seel more movie tickets? &gt; This project was inspired by an article by 538, published in 2015, which can be found here. &gt; Much of my code below is adapted from a capstone project by Jose Portilla in his course &quot;2022 Python for Machine Learning &amp; Data Science Masterclass&quot; on Udemy . Note: . Fandango has 2 rating systems: . Stars: rating in stars 0-5 displayed on their website&#39;s HTML . | Rating: actual true rating numerically shown on the movie&#39;s page. . | . Import Libraries &amp; Data . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . Data . Note: there are 2 primary data sources, both available from 538&#39;s github . The first dataset contains every film that has a Rotten Tomatoe&#39;s rating, a RT User rating, and a Metacritic score, a Metacritic User score, and IMDb score, and at least 30 fan reviews on Fandango. Data from Fandango was pulled Aug. 24, 2015 . all_sites = pd.read_csv(&quot;all_sites_scores.csv&quot;) . all_sites.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 146 entries, 0 to 145 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 FILM 146 non-null object 1 RottenTomatoes 146 non-null int64 2 RottenTomatoes_User 146 non-null int64 3 Metacritic 146 non-null int64 4 Metacritic_User 146 non-null float64 5 IMDB 146 non-null float64 6 Metacritic_user_vote_count 146 non-null int64 7 IMDB_user_vote_count 146 non-null int64 dtypes: float64(2), int64(5), object(1) memory usage: 9.2+ KB . The Fandango dataset contains every film 538 pulled from Fandango . Film: the movie | Stars: the number of stars presented on Fandango.com . | Rating: the Fandango ratingValue for the film, as pulled from the HTML of each page (this is the actual average score the movie obtained) . | Votes: the number of people who had reviewed the film at the time it was pulled. . | . fandango = pd.read_csv(&quot;fandango_scrape.csv&quot;) . Exploratory Data Analysis . First, let&#39;s explore the Fandango dataset . fandango.head() . FILM STARS RATING VOTES . 0 Fifty Shades of Grey (2015) | 4.0 | 3.9 | 34846 | . 1 Jurassic World (2015) | 4.5 | 4.5 | 34390 | . 2 American Sniper (2015) | 5.0 | 4.8 | 34085 | . 3 Furious 7 (2015) | 5.0 | 4.8 | 33538 | . 4 Inside Out (2015) | 4.5 | 4.5 | 15749 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; fandango.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 504 entries, 0 to 503 Data columns (total 4 columns): # Column Non-Null Count Dtype -- -- 0 FILM 504 non-null object 1 STARS 504 non-null float64 2 RATING 504 non-null float64 3 VOTES 504 non-null int64 dtypes: float64(2), int64(1), object(1) memory usage: 15.9+ KB . fandango.describe() . STARS RATING VOTES . count 504.000000 | 504.000000 | 504.000000 | . mean 3.558532 | 3.375794 | 1147.863095 | . std 1.563133 | 1.491223 | 3830.583136 | . min 0.000000 | 0.000000 | 0.000000 | . 25% 3.500000 | 3.100000 | 3.000000 | . 50% 4.000000 | 3.800000 | 18.500000 | . 75% 4.500000 | 4.300000 | 189.750000 | . max 5.000000 | 5.000000 | 34846.000000 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Below, a scatterplot shows the relationship between rating and votes. . plt.figure(figsize=(10,4), dpi=150) sns.scatterplot(data=fandango, x=&#39;RATING&#39;, y=&#39;VOTES&#39;); . Next, the correlation between the columns is shown: . fandango.corr() . STARS RATING VOTES . STARS 1.000000 | 0.994696 | 0.164218 | . RATING 0.994696 | 1.000000 | 0.163764 | . VOTES 0.164218 | 0.163764 | 1.000000 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Now, a new column (YEAR) is created in the dataframe from the year in the title strings, as the total value counts are visualized. . fandango[&#39;YEAR&#39;] = fandango[&#39;FILM&#39;].apply(lambda title:title.split(&#39;(&#39;)[-1]) . fandango[&#39;YEAR&#39;].value_counts() . 2015) 478 2014) 23 2016) 1 1964) 1 2012) 1 Name: YEAR, dtype: int64 . p = sns.countplot(data=fandango, x=&#39;YEAR&#39;); p.set_title(&#39;Total Number of Movies By Year&#39;); . The 10 movies with the highest number of votes are: . fandango.nlargest(10,&#39;VOTES&#39;) . FILM STARS RATING VOTES YEAR . 0 Fifty Shades of Grey (2015) | 4.0 | 3.9 | 34846 | 2015) | . 1 Jurassic World (2015) | 4.5 | 4.5 | 34390 | 2015) | . 2 American Sniper (2015) | 5.0 | 4.8 | 34085 | 2015) | . 3 Furious 7 (2015) | 5.0 | 4.8 | 33538 | 2015) | . 4 Inside Out (2015) | 4.5 | 4.5 | 15749 | 2015) | . 5 The Hobbit: The Battle of the Five Armies (2014) | 4.5 | 4.3 | 15337 | 2014) | . 6 Kingsman: The Secret Service (2015) | 4.5 | 4.2 | 15205 | 2015) | . 7 Minions (2015) | 4.0 | 4.0 | 14998 | 2015) | . 8 Avengers: Age of Ultron (2015) | 5.0 | 4.5 | 14846 | 2015) | . 9 Into the Woods (2014) | 3.5 | 3.4 | 13055 | 2014) | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; And the number of movies with zero votes are: . no_votes = fandango[&#39;VOTES&#39;] == 0 no_votes.sum() . 69 . Now create a new dataframe of only reviewed films (by removing any films that have zero votes) . fan_reviewed = fandango[fandango[&#39;VOTES&#39;]&gt;0] . The article mentioned above discusses the fact that true user ratings may be slightly different than the rating shown to a user (due to HTML and star rating displays). . Can create a KDE plot that displays the distribution of ratings that are displayed (STARS) versus what the true rating was from the votes (RATING) . The KDE&#39;s are clipped to 0-5 . plt.figure(figsize=(10,4), dpi=150) sns.kdeplot(data=fan_reviewed, x=&#39;RATING&#39;, clip=[0,5], fill=True, label = &#39;True Rating&#39;) sns.kdeplot(data=fan_reviewed, x=&#39;STARS&#39;, clip=[0,5], fill=True, label = &#39;Stars Displayed&#39;) plt.legend(loc=(1.05,0.5)); . So, it seems the stars displayed are slightly higher than the true ratings (which may just be due to how the stars are calculated and displayed in the HTML). . Below, we quantify the discrepency. A new column of the difference between the two is created, and the difference is rounded to the nearest decimal point: . fan_reviewed[&#39;STARS_DIFF&#39;] = fan_reviewed[&#39;STARS&#39;] - fan_reviewed[&#39;RATING&#39;] fan_reviewed[&#39;STARS_DIFF&#39;] = fan_reviewed[&#39;STARS_DIFF&#39;].round(2) . fan_reviewed . FILM STARS RATING VOTES YEAR STARS_DIFF . 0 Fifty Shades of Grey (2015) | 4.0 | 3.9 | 34846 | 2015) | 0.1 | . 1 Jurassic World (2015) | 4.5 | 4.5 | 34390 | 2015) | 0.0 | . 2 American Sniper (2015) | 5.0 | 4.8 | 34085 | 2015) | 0.2 | . 3 Furious 7 (2015) | 5.0 | 4.8 | 33538 | 2015) | 0.2 | . 4 Inside Out (2015) | 4.5 | 4.5 | 15749 | 2015) | 0.0 | . ... ... | ... | ... | ... | ... | ... | . 430 That Sugar Film (2015) | 5.0 | 5.0 | 1 | 2015) | 0.0 | . 431 The Intern (2015) | 5.0 | 5.0 | 1 | 2015) | 0.0 | . 432 The Park Bench (2015) | 5.0 | 5.0 | 1 | 2015) | 0.0 | . 433 The Wanted 18 (2015) | 5.0 | 5.0 | 1 | 2015) | 0.0 | . 434 Z For Zachariah (2015) | 5.0 | 5.0 | 1 | 2015) | 0.0 | . 435 rows × 6 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Next, a countplot is used to display the number of times a certain difference occurs . plt.figure(figsize=(12,4), dpi=150) sns.countplot(data=fan_reviewed, x=&#39;STARS_DIFF&#39;, palette=&#39;magma&#39;); . It seems that one move was displaying a 1-star difference from its true rating. That movie is: . fan_reviewed[fan_reviewed[&#39;STARS_DIFF&#39;] == 1] . FILM STARS RATING VOTES YEAR STARS_DIFF . 381 Turbo Kid (2015) | 5.0 | 4.0 | 2 | 2015) | 1.0 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Of course, it only had 2 votes! . Comparison of Fandango Ratings to Other Sites . Below, the Fandango ratings are compared to other the ratings from other sites. . all_sites.head() . FILM RottenTomatoes RottenTomatoes_User Metacritic Metacritic_User IMDB Metacritic_user_vote_count IMDB_user_vote_count . 0 Avengers: Age of Ultron (2015) | 74 | 86 | 66 | 7.1 | 7.8 | 1330 | 271107 | . 1 Cinderella (2015) | 85 | 80 | 67 | 7.5 | 7.1 | 249 | 65709 | . 2 Ant-Man (2015) | 80 | 90 | 64 | 8.1 | 7.8 | 627 | 103660 | . 3 Do You Believe? (2015) | 18 | 84 | 22 | 4.7 | 5.4 | 31 | 3136 | . 4 Hot Tub Time Machine 2 (2015) | 14 | 28 | 29 | 3.4 | 5.1 | 88 | 19560 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; all_sites.describe() . RottenTomatoes RottenTomatoes_User Metacritic Metacritic_User IMDB Metacritic_user_vote_count IMDB_user_vote_count . count 146.000000 | 146.000000 | 146.000000 | 146.000000 | 146.000000 | 146.000000 | 146.000000 | . mean 60.849315 | 63.876712 | 58.808219 | 6.519178 | 6.736986 | 185.705479 | 42846.205479 | . std 30.168799 | 20.024430 | 19.517389 | 1.510712 | 0.958736 | 316.606515 | 67406.509171 | . min 5.000000 | 20.000000 | 13.000000 | 2.400000 | 4.000000 | 4.000000 | 243.000000 | . 25% 31.250000 | 50.000000 | 43.500000 | 5.700000 | 6.300000 | 33.250000 | 5627.000000 | . 50% 63.500000 | 66.500000 | 59.000000 | 6.850000 | 6.900000 | 72.500000 | 19103.000000 | . 75% 89.000000 | 81.000000 | 75.000000 | 7.500000 | 7.400000 | 168.500000 | 45185.750000 | . max 100.000000 | 94.000000 | 94.000000 | 9.600000 | 8.600000 | 2375.000000 | 334164.000000 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Rotten Tomatoes . First, the data from Rotten Tomatoes (RT) is examined. RT has 2 sets of reviews: their critics reviews &amp; their user reviews. . Below shows a scatterplot exploring the relationship between these 2 reviews: . plt.figure(figsize=(10,4), dpi=150) sns.scatterplot(data=all_sites, x=&#39;RottenTomatoes&#39;, y=&#39;RottenTomatoes_User&#39;) plt.xlim(0,100) plt.ylim(0,100); . Next, the difference between the RT critics and users is quantified, by looking at their difference. A difference of 0 means the reviews match. . all_sites[&#39;Rotten_Diff&#39;] = all_sites[&#39;RottenTomatoes&#39;] - all_sites[&#39;RottenTomatoes_User&#39;] . The mean absolute difference between RT critic and user scores is: . all_sites[&#39;Rotten_Diff&#39;].apply(abs).mean() . 15.095890410958905 . Next, the distribution of the differences between the RT critics and users is displayed (using KDE and histogram). . Note: negative scores indicate that the users rated the film much higher than the critics. . plt.figure(figsize=(10,4), dpi=200) sns.histplot(data=all_sites, x=&#39;Rotten_Diff&#39;, kde=True, bins=25) plt.title(&#39;RT Critics Score minus RT User Score&#39;); . Next, the absolute value difference between the RT critics and users scores is shown: . plt.figure(figsize=(10,4),dpi=200) sns.histplot(x=all_sites[&#39;Rotten_Diff&#39;].apply(abs),bins=25,kde=True) plt.title(&quot;Abs Difference between RT Critics Score and RT User Score&quot;); . Now, we&#39;ll try to find out which movies are creating the largest differences. . First, show the top 5 movies with the largest negative difference between Users and RT critics (meaning that users rated the movie much higher on average than the critics did.) . print(&#39;Users Love but Critics Hate&#39;) all_sites.nsmallest(5, &#39;Rotten_Diff&#39;)[[&#39;FILM&#39;, &#39;Rotten_Diff&#39;]] . Users Love but Critics Hate . FILM Rotten_Diff . 3 Do You Believe? (2015) | -66 | . 85 Little Boy (2015) | -61 | . 105 Hitman: Agent 47 (2015) | -42 | . 134 The Longest Ride (2015) | -42 | . 125 The Wedding Ringer (2015) | -39 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Now, the top 5 movies where critics scored the move higher than users are shown: . print(&quot;Critics love, but Users Hate&quot;) all_sites.nlargest(5,&#39;Rotten_Diff&#39;)[[&#39;FILM&#39;,&#39;Rotten_Diff&#39;]] . Critics love, but Users Hate . FILM Rotten_Diff . 69 Mr. Turner (2014) | 42 | . 112 It Follows (2015) | 31 | . 115 While We&#39;re Young (2015) | 31 | . 37 Welcome to Me (2015) | 24 | . 40 I&#39;ll See You In My Dreams (2015) | 24 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; MetaCritic . Next, the ratings for MetaCritic are explored. Like Rotten Tomatoes, MetaCritic also lists an official (critic) and user ratings. . plt.figure(figsize=(10,4), dpi=150) sns.scatterplot(data=all_sites, x=&#39;Metacritic&#39;, y=&#39;Metacritic_User&#39;) plt.xlim(0,100) plt.ylim(0,10); . IMBD . Finally, the data for IMDB are explored. . Note that both MetaCritic and IMDB report back vote counts. . Below, a scatterplot shows the relationship between vote counts on MetaCritic versus vote counts on IMDB: . plt.figure(figsize=(10,4), dpi=150) sns.scatterplot(data=all_sites, x=&#39;Metacritic_user_vote_count&#39;, y=&#39;IMDB_user_vote_count&#39;); . Note that there are 2 outliers. The movie with the highest vote count on IMDB only has 500 Metacritic ratings. . That movie is: . all_sites.nlargest(1,&#39;IMDB_user_vote_count&#39;) . FILM RottenTomatoes RottenTomatoes_User Metacritic Metacritic_User IMDB Metacritic_user_vote_count IMDB_user_vote_count Rotten_Diff . 14 The Imitation Game (2014) | 90 | 92 | 73 | 8.2 | 8.1 | 566 | 334164 | -2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; The movie with the highest Metacritic User Vote count: . all_sites.nlargest(1, &#39;Metacritic_user_vote_count&#39;) . FILM RottenTomatoes RottenTomatoes_User Metacritic Metacritic_User IMDB Metacritic_user_vote_count IMDB_user_vote_count Rotten_Diff . 88 Mad Max: Fury Road (2015) | 97 | 88 | 89 | 8.7 | 8.3 | 2375 | 292023 | 9 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Fandango Scores vs. All Sites . Finally, the question of whether or not Fandango artifically displays higher ratings than warranted is explored. . Below, the Fandango table is combined with the All Sites table. Since some Fandango movies have very little or no reviews, they are not included. An inner merge is used to join the tables. . df = pd.merge(fandango, all_sites, on=&#39;FILM&#39;, how=&#39;inner&#39;) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 145 entries, 0 to 144 Data columns (total 13 columns): # Column Non-Null Count Dtype -- -- 0 FILM 145 non-null object 1 STARS 145 non-null float64 2 RATING 145 non-null float64 3 VOTES 145 non-null int64 4 YEAR 145 non-null object 5 RottenTomatoes 145 non-null int64 6 RottenTomatoes_User 145 non-null int64 7 Metacritic 145 non-null int64 8 Metacritic_User 145 non-null float64 9 IMDB 145 non-null float64 10 Metacritic_user_vote_count 145 non-null int64 11 IMDB_user_vote_count 145 non-null int64 12 Rotten_Diff 145 non-null int64 dtypes: float64(4), int64(7), object(2) memory usage: 15.9+ KB . df.head() . FILM STARS RATING VOTES YEAR RottenTomatoes RottenTomatoes_User Metacritic Metacritic_User IMDB Metacritic_user_vote_count IMDB_user_vote_count Rotten_Diff . 0 Fifty Shades of Grey (2015) | 4.0 | 3.9 | 34846 | 2015) | 25 | 42 | 46 | 3.2 | 4.2 | 778 | 179506 | -17 | . 1 Jurassic World (2015) | 4.5 | 4.5 | 34390 | 2015) | 71 | 81 | 59 | 7.0 | 7.3 | 1281 | 241807 | -10 | . 2 American Sniper (2015) | 5.0 | 4.8 | 34085 | 2015) | 72 | 85 | 72 | 6.6 | 7.4 | 850 | 251856 | -13 | . 3 Furious 7 (2015) | 5.0 | 4.8 | 33538 | 2015) | 81 | 84 | 67 | 6.8 | 7.4 | 764 | 207211 | -3 | . 4 Inside Out (2015) | 4.5 | 4.5 | 15749 | 2015) | 98 | 90 | 94 | 8.9 | 8.6 | 807 | 96252 | 8 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Normalize columns to Fandago STARS and RATINGS 0-5 . Notice that RT, Metacritic, and IMDB don&#39;t use a score between 0-5 stars like Fandango does. . In order to do a fair comparison, we need to normalize these values so they all fall between 0-5 stars, and the relationship between the reviews stays the same. . df[&#39;RT_Norm&#39;] = np.round(df[&#39;RottenTomatoes&#39;]/20,1) df[&#39;RTU_Norm&#39;] = np.round(df[&#39;RottenTomatoes_User&#39;]/20,1) . df[&#39;Meta_Norm&#39;] = np.round(df[&#39;Metacritic&#39;]/20,1) df[&#39;Meta_U_Norm&#39;] = np.round(df[&#39;Metacritic_User&#39;]/2,1) . df[&#39;IMDB_Norm&#39;] = np.round(df[&#39;IMDB&#39;]/2,1) . df.head() . FILM STARS RATING VOTES YEAR RottenTomatoes RottenTomatoes_User Metacritic Metacritic_User IMDB Metacritic_user_vote_count IMDB_user_vote_count Rotten_Diff RT_Norm RTU_Norm Meta_Norm Meta_U_Norm IMDB_Norm . 0 Fifty Shades of Grey (2015) | 4.0 | 3.9 | 34846 | 2015) | 25 | 42 | 46 | 3.2 | 4.2 | 778 | 179506 | -17 | 1.2 | 2.1 | 2.3 | 1.6 | 2.1 | . 1 Jurassic World (2015) | 4.5 | 4.5 | 34390 | 2015) | 71 | 81 | 59 | 7.0 | 7.3 | 1281 | 241807 | -10 | 3.6 | 4.0 | 3.0 | 3.5 | 3.6 | . 2 American Sniper (2015) | 5.0 | 4.8 | 34085 | 2015) | 72 | 85 | 72 | 6.6 | 7.4 | 850 | 251856 | -13 | 3.6 | 4.2 | 3.6 | 3.3 | 3.7 | . 3 Furious 7 (2015) | 5.0 | 4.8 | 33538 | 2015) | 81 | 84 | 67 | 6.8 | 7.4 | 764 | 207211 | -3 | 4.0 | 4.2 | 3.4 | 3.4 | 3.7 | . 4 Inside Out (2015) | 4.5 | 4.5 | 15749 | 2015) | 98 | 90 | 94 | 8.9 | 8.6 | 807 | 96252 | 8 | 4.9 | 4.5 | 4.7 | 4.4 | 4.3 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Now, a norm_scores DataFrame is created that only contains the normalized ratings. Both STARS and RATING from the original Fandango table are included: . norm_scores = df[[&#39;STARS&#39;,&#39;RATING&#39;,&#39;RT_Norm&#39;,&#39;RTU_Norm&#39;,&#39;Meta_Norm&#39;,&#39;Meta_U_Norm&#39;,&#39;IMDB_Norm&#39;]] . norm_scores.head() . STARS RATING RT_Norm RTU_Norm Meta_Norm Meta_U_Norm IMDB_Norm . 0 4.0 | 3.9 | 1.2 | 2.1 | 2.3 | 1.6 | 2.1 | . 1 4.5 | 4.5 | 3.6 | 4.0 | 3.0 | 3.5 | 3.6 | . 2 5.0 | 4.8 | 3.6 | 4.2 | 3.6 | 3.3 | 3.7 | . 3 5.0 | 4.8 | 4.0 | 4.2 | 3.4 | 3.4 | 3.7 | . 4 4.5 | 4.5 | 4.9 | 4.5 | 4.7 | 4.4 | 4.3 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Comparing Distribution of Scores Across Sites . Now the question of whether or not Fandango displays abnormally high ratings can be answered. . Are Fandango&#39;s ratings themselves higher than average? . Below, a plot is created showing the normalized ratings across all sites, using a KDE plot in seaborn: . def move_legend(ax, new_loc, **kws): old_legend = ax.legend_ handles = old_legend.legendHandles labels = [t.get_text() for t in old_legend.get_texts()] title = old_legend.get_title().get_text() ax.legend(handles, labels, loc=new_loc, title=title, **kws) . fig, ax = plt.subplots(figsize=(15,6),dpi=150) sns.kdeplot(data=norm_scores,clip=[0,5],shade=True,palette=&#39;Set1&#39;,ax=ax) move_legend(ax, &quot;upper left&quot;) . It&#39;s pretty obvious from this that Fandango has an uneven distribution. . It seems that RT critics have the most uniform distribution. . Below, the RT critic ratings are compared against the STARS displayed by Fandango: . fig, ax = plt.subplots(figsize=(15,6),dpi=150) sns.kdeplot(data=norm_scores[[&#39;RT_Norm&#39;,&#39;STARS&#39;]],clip=[0,5],shade=True,palette=&#39;Set1&#39;,ax=ax) move_legend(ax, &quot;upper left&quot;) . It seems that Fandango rates all films 2.5 stars or higher, even though there is a more uniform distribution for RT critics. . How are the worst movies rated across all plaforms? . Below, a clustermap shows all of the normalized scores. . sns.clustermap(norm_scores, cmap=&#39;magma&#39;, col_cluster=False); . This too shows that Fandango, unlike the other rating sites, has almost no low-starred movies (note the lack of dark shading in the first two columns, representing STARS and RATINGS in Fandango) . Based off the Rotten Tomatoes critic ratings, what are the top 10 lowest rated movies, and what are the normalized scores across all plaforms for these movies? . norm_films = df[[&#39;STARS&#39;,&#39;RATING&#39;,&#39;RT_Norm&#39;,&#39;RTU_Norm&#39;,&#39;Meta_Norm&#39;,&#39;Meta_U_Norm&#39;,&#39;IMDB_Norm&#39;,&#39;FILM&#39;]] . norm_films.nsmallest(10, &#39;RT_Norm&#39;) . STARS RATING RT_Norm RTU_Norm Meta_Norm Meta_U_Norm IMDB_Norm FILM . 49 3.5 | 3.5 | 0.2 | 1.8 | 0.6 | 1.2 | 2.2 | Paul Blart: Mall Cop 2 (2015) | . 25 4.5 | 4.1 | 0.4 | 2.3 | 1.3 | 2.3 | 3.0 | Taken 3 (2015) | . 28 3.0 | 2.7 | 0.4 | 1.0 | 1.4 | 1.2 | 2.0 | Fantastic Four (2015) | . 54 4.0 | 3.7 | 0.4 | 1.8 | 1.6 | 1.8 | 2.4 | Hot Pursuit (2015) | . 84 4.0 | 3.9 | 0.4 | 2.4 | 1.4 | 1.6 | 3.0 | Hitman: Agent 47 (2015) | . 50 4.0 | 3.6 | 0.5 | 1.8 | 1.5 | 2.8 | 2.3 | The Boy Next Door (2015) | . 77 3.5 | 3.2 | 0.6 | 1.8 | 1.5 | 2.0 | 2.8 | Seventh Son (2015) | . 78 3.5 | 3.2 | 0.6 | 1.5 | 1.4 | 1.6 | 2.8 | Mortdecai (2015) | . 83 3.5 | 3.3 | 0.6 | 1.7 | 1.6 | 2.5 | 2.8 | Sinister 2 (2015) | . 87 3.5 | 3.2 | 0.6 | 1.4 | 1.6 | 1.9 | 2.7 | Unfinished Business (2015) | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Finally, the distribution of ratings across all sites for the top 10 worse movies is visualized: . print(&#39; n n&#39;) plt.figure(figsize=(15,6),dpi=150) worst_films = norm_films.nsmallest(10,&#39;RT_Norm&#39;).drop(&#39;FILM&#39;,axis=1) sns.kdeplot(data=worst_films,clip=[0,5],shade=True,palette=&#39;Set1&#39;) plt.title(&quot;Ratings for RT Critic&#39;s 10 Worst Reviewed Films&quot;); . . Conclusion . Note that Fandango is showing 3-4 star ratings for films that are clearly bad according to the other rating sites. . Thus, at least when this data was pulled in 2015, Fandango is not to be trusted with ratings! .",
            "url": "https://pkalnins.github.io/ws/data%20visualization/pandas/seaborn/2022/08/10/FandangoProject.html",
            "relUrl": "/data%20visualization/pandas/seaborn/2022/08/10/FandangoProject.html",
            "date": " • Aug 10, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://pkalnins.github.io/ws/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About Me . I’m a naturopathic physician and former professor, now training to be a data analyst and data scientist. . My interests include the application of data visualization, analysis, and predictive modeling to improve medical practice and health outcomes, and to advance medical knowledge. . In particular, I have interests in precision medicine (especially using metabolomic data) and real-time monitoring of physiology through non-invasive biosensors (using thermal, electrical, and optical data). . Background . I have practiced as a primary care naturopathic physician since 1998, focusing primarily on offering integrative care for patients with a variety of chronic health conditions. . For much of that time, I served as an Assistant Professor of Naturopathic Medicine at the National University of Natural Medicine (NUNM) in Portland, Oregon. There, I taught various courses in the basic medical sciences (physiology, pharmacology and herbal pharmacology, pathology), evidence-based medicine, and neuroendocrinology. I also attended to patients and supervised students in the university’s outpatient teaching clinics. And through NUNM’s Helfgott Research Institute, I participated in evidence-based research and mentored students. . My primary clinical and research activities have been focused around whole-systems biology and integrative medicine, specifically in understanding how physiological self-regulation (salutogenesis) is mediated through the neuroendocrine-immune and organ systems. I have explored the potential of micronutrient (vitamins, minerals, therapeutic metals) and herbal therapies (both “Western” and East Asian herbal therapies) in helping to restore homeodynamic balance in chronic diseases. . For the past 2 years, I have completed additional training in data analytics/data science, machine learning, software engineering, and database management. . From my years of practice as a primary care physician, I have come to believe that advances in biosensing, real-time monitoring of physiology, and machine learning have the potential to revolutionize clinical care. I have felt a strong desire to pivot from clinical practice to data science so that I can directly contribute to this developing field of study. . Skills: Data Analysis &amp; Data Science . Data gathering, storage, cleaning, visualization, and stastistical analysis; predictive modeling using supervised and unsupervised machine learning and AI . Python (including NumPy, Pandas, Matplolib, Seaborn, Scikit-learn, TensorFlow) | R | SQL | Tableau | Git/Github (version control) | . Software Development . Full stack web development . HTML5/CSS3 | Javascript (including Node.js, Express.js, Mongoose/MongoDB, React.js) | .",
          "url": "https://pkalnins.github.io/ws/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pkalnins.github.io/ws/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}